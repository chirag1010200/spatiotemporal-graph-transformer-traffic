{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceac9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-26T12:05:06.024093Z",
     "iopub.status.busy": "2025-09-26T12:05:06.023763Z",
     "iopub.status.idle": "2025-09-26T12:08:10.001938Z",
     "shell.execute_reply": "2025-09-26T12:08:10.000852Z"
    },
    "papermill": {
     "duration": 183.983315,
     "end_time": "2025-09-26T12:08:10.003516",
     "exception": false,
     "start_time": "2025-09-26T12:05:06.020201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 12:05:12.183356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758888312.556627      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758888312.660891      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Loading traffic data from HDF5 and cleaning data...\n",
      "Loaded traffic data with shape: (34272, 207)\n",
      "2) Attempting to load adjacency matrix from file...\n",
      "Successfully loaded pickle file. Now validating contents...\n",
      "Found valid matrix as an item in a list/tuple.\n",
      "3) Creating spatiotemporal sequences...\n",
      "X_traffic shape: (34260, 12, 207), X_adj shape: (34260, 207, 207), y shape: (34260, 207)\n",
      "5) Using the full dataset for final training...\n",
      "\n",
      "4) Building and training Spatiotemporal Graph Transformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758888333.687495      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1758888333.688359      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ traffic_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adj_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_convolution   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ traffic_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ adj_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_projection    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,312</span> │ graph_convolutio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ input_projection… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_bloc… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">207</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,455</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ traffic_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m207\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ adj_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m207\u001b[0m, \u001b[38;5;34m207\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graph_convolution   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m207\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ traffic_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ adj_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_projection    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m13,312\u001b[0m │ graph_convolutio… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_block   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m33,472\u001b[0m │ input_projection… │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ transformer_bloc… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m207\u001b[0m)       │     \u001b[38;5;34m13,455\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,239</span> (235.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,239\u001b[0m (235.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,239</span> (235.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,239\u001b[0m (235.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758888357.238404      68 service.cc:148] XLA service 0x7eb048108440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758888357.240268      68 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1758888357.240291      68 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1758888357.854421      68 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 13/268\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.3670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758888361.534098      68 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - loss: 0.1703\n",
      "Epoch 2/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0820\n",
      "Epoch 3/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0687\n",
      "Epoch 4/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0522\n",
      "Epoch 5/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0469\n",
      "Epoch 6/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0428\n",
      "Epoch 7/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0410\n",
      "Epoch 8/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0410\n",
      "Epoch 9/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0375\n",
      "Epoch 10/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0376\n",
      "Epoch 11/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0374\n",
      "Epoch 12/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0366\n",
      "Epoch 13/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0349\n",
      "Epoch 14/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0297\n",
      "Epoch 15/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0293\n",
      "Epoch 16/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0257\n",
      "Epoch 17/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0247\n",
      "Epoch 18/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0265\n",
      "Epoch 19/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0255\n",
      "Epoch 20/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0220\n",
      "Epoch 21/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0214\n",
      "Epoch 22/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0206\n",
      "Epoch 23/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0197\n",
      "Epoch 24/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0172\n",
      "Epoch 25/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0170\n",
      "Epoch 26/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0170\n",
      "Epoch 27/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0171\n",
      "Epoch 28/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0162\n",
      "Epoch 29/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0167\n",
      "Epoch 30/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0168\n",
      "Epoch 31/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0167\n",
      "Epoch 32/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0166\n",
      "Epoch 33/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0157\n",
      "Epoch 34/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0151\n",
      "Epoch 35/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0154\n",
      "Epoch 36/36\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0153\n",
      "✅ Final model trained on all data. Saving...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, Dropout, Lambda, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# -------------------- USER PATHS: change if needed --------------------\n",
    "TRAFFIC_H5 = 'data/METR-LA.h5'\n",
    "ADJ_PKL = 'data/adj_METR-LA.pkl'\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# -------------------- USER SETTINGS --------------------\n",
    "N_TIMESTEPS = 12         # Lookback window\n",
    "FORECAST_HORIZON = 1     # Number of steps to predict\n",
    "NUM_EPOCHS = 36         # Increased epochs for better training\n",
    "BATCH_SIZE = 128\n",
    "D_MODEL = 64             # Dimensionality of the model\n",
    "NUM_HEADS = 4            # Number of attention heads in the Transformer\n",
    "DFF = 128                # Dimensionality of the feed-forward network in Transformer\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def load_and_clean_data(h5_path):\n",
    "    \"\"\"Loads and preprocesses the traffic data from an HDF5 file.\"\"\"\n",
    "    print(\"1) Loading traffic data from HDF5 and cleaning data...\")\n",
    "    try:\n",
    "        traffic_df = pd.read_hdf(h5_path, 'df')\n",
    "        if traffic_df.shape[1] > 1 and traffic_df.iloc[:, 0].dtype == 'object':\n",
    "            traffic_df = traffic_df.iloc[:, 1:]\n",
    "        traffic_df = traffic_df.apply(pd.to_numeric, errors='coerce')\n",
    "        if traffic_df.isna().any().any():\n",
    "            traffic_df = traffic_df.fillna(method='ffill').fillna(method='bfill')\n",
    "        traffic_data = traffic_df.values.astype(np.float32)\n",
    "        N_SAMPLES, N_SENSORS = traffic_data.shape\n",
    "        print(f\"Loaded traffic data with shape: {traffic_data.shape}\")\n",
    "        return traffic_data, N_SENSORS\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {h5_path} was not found.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def robust_adjacency_loader(adj_path, n_sensors, traffic_matrix):\n",
    "    \"\"\"\n",
    "    Robustly loads the adjacency matrix and provides a specific error if it fails.\n",
    "    \"\"\"\n",
    "    print(\"2) Attempting to load adjacency matrix from file...\")\n",
    "    \n",
    "    # --- Step 1: Try to load the pickle file ---\n",
    "    try:\n",
    "        with open(adj_path, 'rb') as f:\n",
    "            # The 'latin1' encoding is important for files created with older Python versions.\n",
    "            adj_loaded = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "    except Exception as e:\n",
    "        # If loading fails for ANY reason, print the specific error.\n",
    "        print(f\"\\n--- ERROR ---\")\n",
    "        print(f\"An explicit error occurred while trying to load the pickle file: {e}\")\n",
    "        print(\"Moving to correlation fallback as a result.\")\n",
    "        print(\"---------------\\n\")\n",
    "        \n",
    "        # Since loading failed, go directly to the fallback.\n",
    "        corr = np.corrcoef(traffic_matrix.T)\n",
    "        np.fill_diagonal(corr, 0)\n",
    "        adj = (np.abs(corr) >= 0.30).astype(np.float32)\n",
    "        print(f\"Generated adjacency with shape: {adj.shape}\")\n",
    "        return adj\n",
    "\n",
    "    # --- Step 2: If loading succeeded, try to validate the contents ---\n",
    "    print(\"Successfully loaded pickle file. Now validating contents...\")\n",
    "    \n",
    "    def valid_mat(m):\n",
    "        try:\n",
    "            m = np.asarray(m, dtype=np.float32)\n",
    "            if m.ndim == 2 and m.shape == (n_sensors, n_sensors):\n",
    "                return m\n",
    "        except Exception:\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    # Try common formats within the loaded object\n",
    "    if isinstance(adj_loaded, np.ndarray):\n",
    "        m = valid_mat(adj_loaded)\n",
    "        if m is not None:\n",
    "            print(\"Found valid matrix in numpy.ndarray.\")\n",
    "            return m\n",
    "            \n",
    "    if sp.issparse(adj_loaded):\n",
    "        m = valid_mat(adj_loaded.toarray())\n",
    "        if m is not None:\n",
    "            print(\"Found valid matrix in scipy.sparse object.\")\n",
    "            return m\n",
    "            \n",
    "    if isinstance(adj_loaded, dict):\n",
    "        for key in ['adj', 'adj_mx', 'adj_matrix', 'adjacency', 'A']:\n",
    "            if key in adj_loaded:\n",
    "                m = valid_mat(adj_loaded[key])\n",
    "                if m is not None:\n",
    "                    print(f\"Found valid matrix in dictionary with key: '{key}'.\")\n",
    "                    return m\n",
    "                    \n",
    "    if isinstance(adj_loaded, (list, tuple)):\n",
    "        for item in adj_loaded:\n",
    "            m = valid_mat(item)\n",
    "            if m is not None:\n",
    "                print(\"Found valid matrix as an item in a list/tuple.\")\n",
    "                return m\n",
    "\n",
    "    #  3: If validation fails, use the fallback\n",
    "    print(\"\\n--- WARNING ---\")\n",
    "    print(\"Successfully loaded pickle file, but could not find a valid matrix inside.\")\n",
    "    print(\"Moving to correlation fallback.\")\n",
    "    print(\"---------------\\n\")\n",
    "    \n",
    "    corr = np.corrcoef(traffic_matrix.T)\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    adj = (np.abs(corr) >= 0.30).astype(np.float32)\n",
    "    print(f\"Generated adjacency with shape: {adj.shape}\")\n",
    "    return adj\n",
    "\n",
    "def create_spatiotemporal_sequences(data, adj_matrix, n_steps, horizon):\n",
    "    \"\"\"Creates sequences for the Spatiotemporal Transformer.\"\"\"\n",
    "    print(\"3) Creating spatiotemporal sequences...\")\n",
    "    X_traffic, y = [], []\n",
    "    for i in range(len(data) - n_steps - horizon + 1):\n",
    "        X_traffic.append(data[i : i + n_steps, :])\n",
    "        y.append(data[i + n_steps : i + n_steps + horizon, :])\n",
    "    X_adj = np.tile(adj_matrix, (len(X_traffic), 1, 1))\n",
    "    X_traffic = np.array(X_traffic)\n",
    "    y = np.array(y).reshape(-1, data.shape[1] * horizon)\n",
    "    print(f\"X_traffic shape: {X_traffic.shape}, X_adj shape: {X_adj.shape}, y shape: {y.shape}\")\n",
    "    return X_traffic, X_adj, y\n",
    "\n",
    "#  Custom Transformer Layers (from your second script)\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "        \n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += mask\n",
    "            \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
    "        return self.dense(output), attention_weights\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "# --- Build and Train Combined Model ---\n",
    "def build_and_train_graph_transformer(X_train, y_train, adj_mx, n_sensors, n_timesteps, horizon):\n",
    "    \"\"\"\n",
    "    Builds and trains the combined Spatiotemporal Graph Transformer model.\n",
    "    \"\"\"\n",
    "    print(\"\\n4) Building and training Spatiotemporal Graph Transformer model...\")\n",
    "    \n",
    "    # Define the two inputs for the model\n",
    "    traffic_input = Input(shape=(n_timesteps, n_sensors), name='traffic_input')\n",
    "    adj_input = Input(shape=(n_sensors, n_sensors), name='adj_input')\n",
    "\n",
    "    # --- Step 1: Spatial Encoding (GNN Layer) ---\n",
    "    # This layer uses the adjacency matrix to mix neighbor information.\n",
    "    # It performs the graph convolution from your first script.\n",
    "    graph_conv_output = Lambda(lambda x: tf.einsum('ijk,ikl->ijl', x[0], x[1]),\n",
    "                               output_shape=(n_timesteps, n_sensors),\n",
    "                               name='graph_convolution')([traffic_input, adj_input])\n",
    "    \n",
    "    # A Dense layer projects the raw sensor data into the model's main dimension (D_MODEL)\n",
    "    # This allows the model to learn a richer representation for each sensor.\n",
    "    projected_input = Dense(D_MODEL, name='input_projection')(graph_conv_output)\n",
    "\n",
    "    # --- Step 2: Temporal Encoding (Transformer Block) ---\n",
    "    # The spatially-aware data is now fed into the Transformer to learn temporal patterns.\n",
    "    transformer_block = TransformerBlock(D_MODEL, NUM_HEADS, DFF)\n",
    "    transformer_output = transformer_block(projected_input, training=True, mask=None)\n",
    "\n",
    "    # --- Step 3: Final Prediction Head ---\n",
    "    # We use GlobalAveragePooling1D to aggregate the features over the time dimension.\n",
    "    # This creates a single feature vector that summarizes the entire time sequence.\n",
    "    pooled_output = GlobalAveragePooling1D()(transformer_output)\n",
    "    \n",
    "    # A final Dense layer makes the forecast for all sensors.\n",
    "    output_layer = Dense(n_sensors * horizon, activation='relu', name='output_layer')(pooled_output)\n",
    "\n",
    "    # Create the complete model\n",
    "    model = Model(inputs=[traffic_input, adj_input], outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Print a summary of the model architecture\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit([X_train, adj_mx], y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- Main Pipeline Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    traffic_data, N_SENSORS = load_and_clean_data(TRAFFIC_H5)\n",
    "    if traffic_data is None:\n",
    "        exit()\n",
    "\n",
    "    adj_mx = robust_adjacency_loader(ADJ_PKL, N_SENSORS, traffic_data)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(traffic_data)\n",
    "    X_traffic, X_adj, y = create_spatiotemporal_sequences(scaled_data, adj_mx, N_TIMESTEPS, FORECAST_HORIZON)\n",
    "\n",
    "    # Use a sequential split for time series data to prevent data leakage\n",
    "    print(\"5) Using the full dataset for final training...\")\n",
    "    \n",
    "    # Note: We pass the full X_adj here, not a split version\n",
    "    model = build_and_train_graph_transformer(X_traffic, y, X_adj, N_SENSORS, N_TIMESTEPS, FORECAST_HORIZON)\n",
    "    \n",
    "    print(\"✅ Final model trained on all data. Saving...\")\n",
    "    model.save('final_graph_transformer_model.h5')\n",
    "        \n",
    "    # Visualization\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4013295,
     "sourceId": 7692357,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 193.121085,
   "end_time": "2025-09-26T12:08:13.223296",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-26T12:05:00.102211",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
